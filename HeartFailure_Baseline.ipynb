{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Raw-Data\" data-toc-modified-id=\"Import-Raw-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Raw Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Raw-Data-Describtion\" data-toc-modified-id=\"Raw-Data-Describtion-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Raw Data Describtion</a></span></li></ul></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dealing-with-some-non-numeric-features\" data-toc-modified-id=\"Dealing-with-some-non-numeric-features-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Dealing with some non-numeric features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Baseline-Dataset\" data-toc-modified-id=\"Baseline-Dataset-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Baseline Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#TOBACCO_STATUS_LABEL\" data-toc-modified-id=\"TOBACCO_STATUS_LABEL-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>TOBACCO_STATUS_LABEL</a></span></li><li><span><a href=\"#RACE\" data-toc-modified-id=\"RACE-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>RACE</a></span></li><li><span><a href=\"#BLOOD_TYPE\" data-toc-modified-id=\"BLOOD_TYPE-2.1.1.3\"><span class=\"toc-item-num\">2.1.1.3&nbsp;&nbsp;</span>BLOOD_TYPE</a></span></li><li><span><a href=\"#FINANCIAL_CLASS_CODE\" data-toc-modified-id=\"FINANCIAL_CLASS_CODE-2.1.1.4\"><span class=\"toc-item-num\">2.1.1.4&nbsp;&nbsp;</span>FINANCIAL_CLASS_CODE</a></span></li></ul></li><li><span><a href=\"#Admissions-Dataset\" data-toc-modified-id=\"Admissions-Dataset-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Admissions Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#PATIENT_TYPE_CODE\" data-toc-modified-id=\"PATIENT_TYPE_CODE-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>PATIENT_TYPE_CODE</a></span></li><li><span><a href=\"#HOSP_ROLLUP_GROUPING1\" data-toc-modified-id=\"HOSP_ROLLUP_GROUPING1-2.1.2.2\"><span class=\"toc-item-num\">2.1.2.2&nbsp;&nbsp;</span>HOSP_ROLLUP_GROUPING1</a></span></li></ul></li><li><span><a href=\"#Drop-all-non-numeric-features\" data-toc-modified-id=\"Drop-all-non-numeric-features-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Drop all non-numeric features</a></span></li></ul></li><li><span><a href=\"#Dealing-with-Missing-Values\" data-toc-modified-id=\"Dealing-with-Missing-Values-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Dealing with Missing Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Drop-columns-with-more-than-1%-NA-values\" data-toc-modified-id=\"Drop-columns-with-more-than-1%-NA-values-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Drop columns with more than 1% NA values</a></span></li><li><span><a href=\"#Filling-'HOSP_CR',-'HOSP_NA',-'HOSP_EGFR'-with-mean-values\" data-toc-modified-id=\"Filling-'HOSP_CR',-'HOSP_NA',-'HOSP_EGFR'-with-mean-values-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Filling 'HOSP_CR', 'HOSP_NA', 'HOSP_EGFR' with mean values</a></span></li><li><span><a href=\"#Filling-'ASA_00',-'INSULIN_00-',-...-with-0\" data-toc-modified-id=\"Filling-'ASA_00',-'INSULIN_00-',-...-with-0-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Filling 'ASA_00', 'INSULIN_00 ', ... with 0</a></span></li></ul></li><li><span><a href=\"#Join-2-datasets-together\" data-toc-modified-id=\"Join-2-datasets-together-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Join 2 datasets together</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deal-with-procudures-during-hospitalization-features\" data-toc-modified-id=\"Deal-with-procudures-during-hospitalization-features-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Deal with procudures during hospitalization features</a></span></li><li><span><a href=\"#Concatenate-two-datasets-together\" data-toc-modified-id=\"Concatenate-two-datasets-together-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Concatenate two datasets together</a></span></li></ul></li><li><span><a href=\"#Normalize-data\" data-toc-modified-id=\"Normalize-data-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Normalize data</a></span></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Feedforward-Neural-Net\" data-toc-modified-id=\"Feedforward-Neural-Net-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Feedforward Neural Net</a></span></li><li><span><a href=\"#Voting-Classifier\" data-toc-modified-id=\"Voting-Classifier-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Voting Classifier</a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>SVM</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Visualization</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Raw Data\n",
    "- raw_baselinedt\n",
    "- raw_admissiondt\n",
    "\n",
    "HF-Baseline:\\\n",
    "Represents the initial encounter with UPMC with a diagnosis of hear failure\n",
    "\n",
    "HF-Admissions: \\\n",
    "Represents subsequent admissions of those patients with heart failure \\\n",
    "\n",
    "12285 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'datasets'\n",
      "/Users/jinchenxie/Desktop/Research/datasets\n"
     ]
    }
   ],
   "source": [
    "%cd datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_baselinedt = pd.read_excel('HF-Baseline.xlsx', '00480_Baseline_20200115_NA')\n",
    "\n",
    "raw_admissiondt = pd.read_excel('HF-Admissions.xlsx', '00480_Admissions_20200115_NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Describtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the baseline dataset has shape (12285, 320)\n",
      "the admissions dataset has shape (55742, 168)\n"
     ]
    }
   ],
   "source": [
    "print(\"the baseline dataset has shape\", raw_baselinedt.shape)\n",
    "print(\"the admissions dataset has shape\", raw_admissiondt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rID</th>\n",
       "      <th>LOS_DAYS</th>\n",
       "      <th>HOSP_CR</th>\n",
       "      <th>HOSP_BILI</th>\n",
       "      <th>HOSP_INR</th>\n",
       "      <th>HOSP_NA</th>\n",
       "      <th>HOSP_EGFR</th>\n",
       "      <th>PRIMARY_DIAGNOSIS_CODE</th>\n",
       "      <th>PRIMARY_DIAGNOSIS_DESCRIPTION</th>\n",
       "      <th>AGE_ADMISSION</th>\n",
       "      <th>AGE_OFFICE_VISIT</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNIC_GROUP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>WEIGHT_KG</th>\n",
       "      <th>ORD</th>\n",
       "      <th>DAYS_TO_CLOSEST_OFFICE_VISIT</th>\n",
       "      <th>DEPARTMENT_NAME</th>\n",
       "      <th>EXTERNAL_DEPARTMENT_NAME</th>\n",
       "      <th>DEPARTMENT_SPECIALTY</th>\n",
       "      <th>BP_SYSTOLIC</th>\n",
       "      <th>BP_DIASTOLIC</th>\n",
       "      <th>PULSE</th>\n",
       "      <th>FINANCIAL_CLASS_CODE</th>\n",
       "      <th>...</th>\n",
       "      <th>BNP_DAYS</th>\n",
       "      <th>BILI</th>\n",
       "      <th>BILI_DAYS</th>\n",
       "      <th>INR</th>\n",
       "      <th>INR_DAYS</th>\n",
       "      <th>BLOOD_TYPE</th>\n",
       "      <th>CLOSEST_MELD</th>\n",
       "      <th>VERIFIED_MELD</th>\n",
       "      <th>MELD_EST_MORTALITY</th>\n",
       "      <th>RHC_FOUND</th>\n",
       "      <th>RA_MEAN_PRESSURE</th>\n",
       "      <th>RA_MEAN_PRESSURE_DAYS</th>\n",
       "      <th>THERMAL_CARDIAC_INDEX</th>\n",
       "      <th>THERMAL_CARDIAC_INDEX_DAYS</th>\n",
       "      <th>FICK_CARDIAC_INDEX</th>\n",
       "      <th>FICK_CARDIAC_INDEX_DAYS</th>\n",
       "      <th>PA_SATURATION</th>\n",
       "      <th>PA_SATURATION_DAYS</th>\n",
       "      <th>WEDGE_MEAN_PRESSURE</th>\n",
       "      <th>WEDGE_MEAN_PRESSURE_DAYS</th>\n",
       "      <th>PULM_ART_SYS_PRESSURE</th>\n",
       "      <th>PULM_ART_SYS_PRESSURE_DAYS</th>\n",
       "      <th>CTB</th>\n",
       "      <th>FOLLOWUP_DAYS</th>\n",
       "      <th>AGE_CENSOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.198</td>\n",
       "      <td>3.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>17.75</td>\n",
       "      <td>I50.43</td>\n",
       "      <td>ACUTE ON CHRONIC COMBINED</td>\n",
       "      <td>82</td>\n",
       "      <td>82.9</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>28.28</td>\n",
       "      <td>84.37</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>XMEDICOR ASSOC ERIE</td>\n",
       "      <td>XMedicor Associates Inc</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>118.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AB+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.240</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>136.0</td>\n",
       "      <td>47.45</td>\n",
       "      <td>428.21</td>\n",
       "      <td>AC SYSTOL HEART FAILURE</td>\n",
       "      <td>91</td>\n",
       "      <td>91.6</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>21.41</td>\n",
       "      <td>60.65</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>GM HBC SHEA</td>\n",
       "      <td>Shea Medical Center</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>110.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.059244</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.074</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>22.46</td>\n",
       "      <td>428.33</td>\n",
       "      <td>AC-CHR DIASTOL HRT FAIL</td>\n",
       "      <td>76</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>28.58</td>\n",
       "      <td>80.29</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>SFM HAMPTON</td>\n",
       "      <td>SUPERIOR FAM MD HAMPTON</td>\n",
       "      <td>Family Practice</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>MS</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.254738</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1268</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8.128</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>139.0</td>\n",
       "      <td>35.85</td>\n",
       "      <td>I50.33</td>\n",
       "      <td>ACUTE ON CHRONIC DIASTOLIC</td>\n",
       "      <td>66</td>\n",
       "      <td>66.1</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>31.32</td>\n",
       "      <td>90.72</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>CA HAMOT</td>\n",
       "      <td>UPMC Hamot Flagship CVT Surgeons</td>\n",
       "      <td>Cardiac Surgery</td>\n",
       "      <td>108.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>O+</td>\n",
       "      <td>23.323969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1463</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.121</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>141.0</td>\n",
       "      <td>91.09</td>\n",
       "      <td>I50.23</td>\n",
       "      <td>ACUTE ON CHRONIC SYSTOLIC</td>\n",
       "      <td>51</td>\n",
       "      <td>51.3</td>\n",
       "      <td>0</td>\n",
       "      <td>Black</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>44.74</td>\n",
       "      <td>153.77</td>\n",
       "      <td>1</td>\n",
       "      <td>-63</td>\n",
       "      <td>XHVI MERCY OFC</td>\n",
       "      <td>HVI at Mercy</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>140.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>UX</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.872816</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rID  LOS_DAYS  HOSP_CR  HOSP_BILI  HOSP_INR  HOSP_NA  HOSP_EGFR  \\\n",
       "0    1     6.198     3.34        NaN       NaN    136.0      17.75   \n",
       "1    2     3.240     1.40        2.8       1.4    136.0      47.45   \n",
       "2    3     4.074     2.76        2.1       3.0    141.0      22.46   \n",
       "3    4     8.128     1.89        NaN       7.6    139.0      35.85   \n",
       "4    5     3.121     1.04        1.0       1.1    141.0      91.09   \n",
       "\n",
       "  PRIMARY_DIAGNOSIS_CODE PRIMARY_DIAGNOSIS_DESCRIPTION  AGE_ADMISSION  \\\n",
       "0                 I50.43     ACUTE ON CHRONIC COMBINED             82   \n",
       "1                 428.21       AC SYSTOL HEART FAILURE             91   \n",
       "2                 428.33       AC-CHR DIASTOL HRT FAIL             76   \n",
       "3                 I50.33    ACUTE ON CHRONIC DIASTOLIC             66   \n",
       "4                 I50.23     ACUTE ON CHRONIC SYSTOLIC             51   \n",
       "\n",
       "   AGE_OFFICE_VISIT  FEMALE   RACE            ETHNIC_GROUP    BMI  WEIGHT_KG  \\\n",
       "0              82.9       0  White  Not Hispanic or Latino  28.28      84.37   \n",
       "1              91.6       0  White  Not Hispanic or Latino  21.41      60.65   \n",
       "2              76.9       0  White  Not Hispanic or Latino  28.58      80.29   \n",
       "3              66.1       0  White  Not Hispanic or Latino  31.32      90.72   \n",
       "4              51.3       0  Black  Not Hispanic or Latino  44.74     153.77   \n",
       "\n",
       "   ORD  DAYS_TO_CLOSEST_OFFICE_VISIT      DEPARTMENT_NAME  \\\n",
       "0    1                            14  XMEDICOR ASSOC ERIE   \n",
       "1    1                            35          GM HBC SHEA   \n",
       "2    1                            16          SFM HAMPTON   \n",
       "3    1                             9             CA HAMOT   \n",
       "4    1                           -63       XHVI MERCY OFC   \n",
       "\n",
       "           EXTERNAL_DEPARTMENT_NAME DEPARTMENT_SPECIALTY  BP_SYSTOLIC  \\\n",
       "0           XMedicor Associates Inc           Cardiology        118.0   \n",
       "1               Shea Medical Center    Internal Medicine        110.0   \n",
       "2           SUPERIOR FAM MD HAMPTON      Family Practice        100.0   \n",
       "3  UPMC Hamot Flagship CVT Surgeons      Cardiac Surgery        108.0   \n",
       "4                      HVI at Mercy           Cardiology        140.0   \n",
       "\n",
       "   BP_DIASTOLIC  PULSE FINANCIAL_CLASS_CODE  ... BNP_DAYS BILI BILI_DAYS  INR  \\\n",
       "0          58.0   72.0                    M  ...    -14.0  NaN       NaN  NaN   \n",
       "1          58.0   84.0                    M  ...      NaN  0.7       1.0  1.1   \n",
       "2          50.0   80.0                   MS  ...    -16.0  2.1     -15.0  1.3   \n",
       "3          62.0   90.0                    M  ...     -9.0  0.9     -23.0  2.0   \n",
       "4         100.0   78.0                   UX  ...    -19.0  NaN       NaN  NaN   \n",
       "\n",
       "   INR_DAYS  BLOOD_TYPE  CLOSEST_MELD  VERIFIED_MELD  MELD_EST_MORTALITY  \\\n",
       "0       NaN         AB+           NaN            NaN                 NaN   \n",
       "1     -11.0         NaN     18.059244           -1.0                 6.0   \n",
       "2       7.0         NaN     31.254738           -1.0                52.6   \n",
       "3      -1.0          O+     23.323969            0.0                19.6   \n",
       "4       NaN         NaN      7.872816           -1.0                 1.9   \n",
       "\n",
       "   RHC_FOUND  RA_MEAN_PRESSURE  RA_MEAN_PRESSURE_DAYS  THERMAL_CARDIAC_INDEX  \\\n",
       "0          0               NaN                    NaN                    NaN   \n",
       "1          0               NaN                    NaN                    NaN   \n",
       "2          0               NaN                    NaN                    NaN   \n",
       "3          0               NaN                    NaN                    NaN   \n",
       "4          0               NaN                    NaN                    NaN   \n",
       "\n",
       "   THERMAL_CARDIAC_INDEX_DAYS  FICK_CARDIAC_INDEX  FICK_CARDIAC_INDEX_DAYS  \\\n",
       "0                         NaN                 NaN                      NaN   \n",
       "1                         NaN                 NaN                      NaN   \n",
       "2                         NaN                 NaN                      NaN   \n",
       "3                         NaN                 NaN                      NaN   \n",
       "4                         NaN                 NaN                      NaN   \n",
       "\n",
       "   PA_SATURATION  PA_SATURATION_DAYS  WEDGE_MEAN_PRESSURE  \\\n",
       "0            NaN                 NaN                  NaN   \n",
       "1            NaN                 NaN                  NaN   \n",
       "2            NaN                 NaN                  NaN   \n",
       "3            NaN                 NaN                  NaN   \n",
       "4            NaN                 NaN                  NaN   \n",
       "\n",
       "   WEDGE_MEAN_PRESSURE_DAYS  PULM_ART_SYS_PRESSURE  \\\n",
       "0                       NaN                    NaN   \n",
       "1                       NaN                    NaN   \n",
       "2                       NaN                    NaN   \n",
       "3                       NaN                    NaN   \n",
       "4                       NaN                    NaN   \n",
       "\n",
       "   PULM_ART_SYS_PRESSURE_DAYS  CTB FOLLOWUP_DAYS  AGE_CENSOR  \n",
       "0                         NaN    1           391          83  \n",
       "1                         NaN    1           439          92  \n",
       "2                         NaN    1          1268          80  \n",
       "3                         NaN    0          1463          70  \n",
       "4                         NaN    0          1407          55  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_baselinedt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baseline dataset has 320 features including 'rID'. 291 numerical features, and 29 string features.\n",
    "- Admissions dataset has 168 features also including 'rID'. 143 numerical features, and 25 string features.\n",
    "- Each patient has exactly 1 row in baseline dataset, but can have multiple rows in admissions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with some non-numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_DIAGNOSIS_CODE</th>\n",
       "      <th>PRIMARY_DIAGNOSIS_DESCRIPTION</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNIC_GROUP</th>\n",
       "      <th>DEPARTMENT_NAME</th>\n",
       "      <th>EXTERNAL_DEPARTMENT_NAME</th>\n",
       "      <th>DEPARTMENT_SPECIALTY</th>\n",
       "      <th>FINANCIAL_CLASS_CODE</th>\n",
       "      <th>FINANCIAL_CLASS</th>\n",
       "      <th>HOSP_ROLLUP_GROUPING1</th>\n",
       "      <th>HOSP_ROLLUP_GROUPING2</th>\n",
       "      <th>CLOSEST_PS_DAYS</th>\n",
       "      <th>CLOSEST_TS_DAYS</th>\n",
       "      <th>PRE_TRANSPLANT_DAYS</th>\n",
       "      <th>PRIOR_PCI_DAYS</th>\n",
       "      <th>PRIOR_CABG_DAYS</th>\n",
       "      <th>PRIOR_TAVR_DAYS</th>\n",
       "      <th>PRIOR_SAVR_MECH_DAYS</th>\n",
       "      <th>PRIOR_SURG_AO_GRFT_DAYS</th>\n",
       "      <th>PRIOR_ENDO_AO_GRFT_DAYS</th>\n",
       "      <th>PRIOR_AO_VLV_REPAIR_DAYS</th>\n",
       "      <th>PRIOR_SMVR_DAYS</th>\n",
       "      <th>PRIOR_SPVR_DAYS</th>\n",
       "      <th>PRIOR_STVR_DAYS</th>\n",
       "      <th>TOBACCO_STATUS_LABEL</th>\n",
       "      <th>HF_ETIOLOGY_LABEL</th>\n",
       "      <th>LDL_DAYS</th>\n",
       "      <th>PREALBUMIN_DAYS</th>\n",
       "      <th>BLOOD_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I50.43</td>\n",
       "      <td>ACUTE ON CHRONIC COMBINED</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>XMEDICOR ASSOC ERIE</td>\n",
       "      <td>XMedicor Associates Inc</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>M</td>\n",
       "      <td>MEDICARE PART A</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUIT (UNKNOWN TIMEFRAME)</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>428.21</td>\n",
       "      <td>AC SYSTOL HEART FAILURE</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>GM HBC SHEA</td>\n",
       "      <td>Shea Medical Center</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>M</td>\n",
       "      <td>MEDICARE PART A</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>428.33</td>\n",
       "      <td>AC-CHR DIASTOL HRT FAIL</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>SFM HAMPTON</td>\n",
       "      <td>SUPERIOR FAM MD HAMPTON</td>\n",
       "      <td>Family Practice</td>\n",
       "      <td>MS</td>\n",
       "      <td>SECURITY BLUE HMO</td>\n",
       "      <td>Security Blue</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I50.33</td>\n",
       "      <td>ACUTE ON CHRONIC DIASTOLIC</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>CA HAMOT</td>\n",
       "      <td>UPMC Hamot Flagship CVT Surgeons</td>\n",
       "      <td>Cardiac Surgery</td>\n",
       "      <td>M</td>\n",
       "      <td>MEDICARE PART A</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUIT (UNKNOWN TIMEFRAME)</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>O+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I50.23</td>\n",
       "      <td>ACUTE ON CHRONIC SYSTOLIC</td>\n",
       "      <td>Black</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>XHVI MERCY OFC</td>\n",
       "      <td>HVI at Mercy</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>UX</td>\n",
       "      <td>UPMC EX SEL REG HMO</td>\n",
       "      <td>UPMC Commercial</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRIMARY_DIAGNOSIS_CODE PRIMARY_DIAGNOSIS_DESCRIPTION   RACE  \\\n",
       "0                 I50.43     ACUTE ON CHRONIC COMBINED  White   \n",
       "1                 428.21       AC SYSTOL HEART FAILURE  White   \n",
       "2                 428.33       AC-CHR DIASTOL HRT FAIL  White   \n",
       "3                 I50.33    ACUTE ON CHRONIC DIASTOLIC  White   \n",
       "4                 I50.23     ACUTE ON CHRONIC SYSTOLIC  Black   \n",
       "\n",
       "             ETHNIC_GROUP      DEPARTMENT_NAME  \\\n",
       "0  Not Hispanic or Latino  XMEDICOR ASSOC ERIE   \n",
       "1  Not Hispanic or Latino          GM HBC SHEA   \n",
       "2  Not Hispanic or Latino          SFM HAMPTON   \n",
       "3  Not Hispanic or Latino             CA HAMOT   \n",
       "4  Not Hispanic or Latino       XHVI MERCY OFC   \n",
       "\n",
       "           EXTERNAL_DEPARTMENT_NAME DEPARTMENT_SPECIALTY FINANCIAL_CLASS_CODE  \\\n",
       "0           XMedicor Associates Inc           Cardiology                    M   \n",
       "1               Shea Medical Center    Internal Medicine                    M   \n",
       "2           SUPERIOR FAM MD HAMPTON      Family Practice                   MS   \n",
       "3  UPMC Hamot Flagship CVT Surgeons      Cardiac Surgery                    M   \n",
       "4                      HVI at Mercy           Cardiology                   UX   \n",
       "\n",
       "       FINANCIAL_CLASS HOSP_ROLLUP_GROUPING1 HOSP_ROLLUP_GROUPING2  \\\n",
       "0      MEDICARE PART A              Medicare              Medicare   \n",
       "1      MEDICARE PART A              Medicare              Medicare   \n",
       "2    SECURITY BLUE HMO         Security Blue              Medicare   \n",
       "3      MEDICARE PART A              Medicare              Medicare   \n",
       "4  UPMC EX SEL REG HMO       UPMC Commercial            Commercial   \n",
       "\n",
       "  CLOSEST_PS_DAYS CLOSEST_TS_DAYS PRE_TRANSPLANT_DAYS PRIOR_PCI_DAYS  \\\n",
       "0             NaN             NaN                 NaN            NaN   \n",
       "1             NaN             NaN                 NaN            NaN   \n",
       "2             NaN             NaN                 NaN            NaN   \n",
       "3             NaN             NaN                 NaN            NaN   \n",
       "4             NaN             NaN                 NaN            NaN   \n",
       "\n",
       "  PRIOR_CABG_DAYS PRIOR_TAVR_DAYS PRIOR_SAVR_MECH_DAYS  \\\n",
       "0             NaN             NaN                  NaN   \n",
       "1             NaN             NaN                  NaN   \n",
       "2             NaN             NaN                  NaN   \n",
       "3             NaN             NaN                  NaN   \n",
       "4             NaN             NaN                  NaN   \n",
       "\n",
       "  PRIOR_SURG_AO_GRFT_DAYS PRIOR_ENDO_AO_GRFT_DAYS PRIOR_AO_VLV_REPAIR_DAYS  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     NaN                     NaN                      NaN   \n",
       "2                     NaN                     NaN                      NaN   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "  PRIOR_SMVR_DAYS PRIOR_SPVR_DAYS PRIOR_STVR_DAYS      TOBACCO_STATUS_LABEL  \\\n",
       "0             NaN             NaN             NaN  QUIT (UNKNOWN TIMEFRAME)   \n",
       "1             NaN             NaN             NaN                     NEVER   \n",
       "2             NaN             NaN             NaN                     NEVER   \n",
       "3               -             NaN             NaN  QUIT (UNKNOWN TIMEFRAME)   \n",
       "4             NaN             NaN             NaN                   CURRENT   \n",
       "\n",
       "  HF_ETIOLOGY_LABEL LDL_DAYS PREALBUMIN_DAYS BLOOD_TYPE  \n",
       "0             OTHER      NaN             NaN        AB+  \n",
       "1             OTHER      NaN             NaN        NaN  \n",
       "2             OTHER      NaN             NaN        NaN  \n",
       "3             OTHER      NaN               -         O+  \n",
       "4             OTHER      NaN             NaN        NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_bs = raw_baselinedt.select_dtypes(include=['object']).copy()\n",
    "obj_bs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Categorical features to encode:\n",
    "- RACE\n",
    "- FINANCIAL_CLASS_CODE\n",
    "- BLOOD_TYPE\n",
    "- TOBACCO_STATUS_LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOBACCO_STATUS_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QUIT (UNKNOWN TIMEFRAME)        5216\n",
       "NEVER                           4579\n",
       "CURRENT                         1181\n",
       "REMOTE (MORE THAN 12 MONTHS)     502\n",
       "RECENT (WITHIN 12 MONTHS)        425\n",
       "UNKNOWN                          266\n",
       "NEVER ASKED                       82\n",
       "PASSIVE                           34\n",
       "Name: TOBACCO_STATUS_LABEL, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_bs['TOBACCO_STATUS_LABEL'].value_counts()#### BLOOD_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6143\n",
       "0    4579\n",
       "3    1181\n",
       "2     382\n",
       "Name: TOBACCO_STATUS_LABEL, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Level encoding\n",
    "clean_nums = {\"TOBACCO_STATUS_LABEL\": {\"NEVER\": 0, \"QUIT (UNKNOWN TIMEFRAME)\": 1,\n",
    "                                   \"REMOTE (MORE THAN 12 MONTHS)\": 1, \"RECENT (WITHIN 12 MONTHS)\": 1,\n",
    "                                  \"UNKNOWN\": 2, \"NEVER ASKED\": 2,\n",
    "                                  \"PASSIVE\": 2, \"CURRENT\": 3}}\n",
    "obj_bs.replace(clean_nums, inplace=True)\n",
    "obj_bs['TOBACCO_STATUS_LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White      10682\n",
       "Black       1466\n",
       "Decline       32\n",
       "Not Spe       28\n",
       "Other A       16\n",
       "Indian         9\n",
       "America        5\n",
       "Vietnam        4\n",
       "Filipin        4\n",
       "Chinese        4\n",
       "Alaska         3\n",
       "Korean         1\n",
       "Other P        1\n",
       "Name: RACE, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_bs.RACE.isna().sum()\n",
    "obj_bs['RACE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10682\n",
       "0     1603\n",
       "Name: RACE, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Race categories encoding\n",
    "obj_bs = obj_bs.fillna({\"RACE\": \"Other P\"})\n",
    "clean_nums = {\"RACE\": {\"Others\": 0,\"Decline\": 0,\"Not Spe\": 0,\"Other A\": 0,\"Indian\": 0,\n",
    "                       \"America\": 0,\"Vietnam\": 0,\"Filipin\": 0,\"Chinese\": 0,\"Alaska\": 0,\n",
    "                       \"Other P\": 0,\"Korean\": 0, \"Black\": 0,\n",
    "                                   \"White\": 1}}\n",
    "obj_bs.replace(clean_nums, inplace=True)\n",
    "obj_bs['RACE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLOOD_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8619"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_bs.BLOOD_TYPE.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINANCIAL_CLASS_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M     4144\n",
       "MS    2469\n",
       "UM    1966\n",
       "Q      483\n",
       "AD     472\n",
       "BE     335\n",
       "UH     310\n",
       "GG     230\n",
       "2      189\n",
       "MC     187\n",
       "MU     136\n",
       "S      128\n",
       "GA     124\n",
       "US      83\n",
       "XL      81\n",
       "P       81\n",
       "2M      74\n",
       "UY      63\n",
       "2S      58\n",
       "UE      56\n",
       "0       55\n",
       "HA      49\n",
       "UN      42\n",
       "4H      39\n",
       "CG      37\n",
       "MP      30\n",
       "C       28\n",
       "B       28\n",
       "UX      27\n",
       "3B      24\n",
       "VA      20\n",
       "UT      20\n",
       "CB      16\n",
       "4N      14\n",
       "SA      13\n",
       "AT      12\n",
       "2G      11\n",
       "2A      11\n",
       "6       10\n",
       "2C       9\n",
       "AP       9\n",
       "3G       7\n",
       "SM       7\n",
       "H        7\n",
       "R        6\n",
       "3L       5\n",
       "AC       5\n",
       "2U       4\n",
       "4U       4\n",
       "D        4\n",
       "HP       4\n",
       "N        4\n",
       "CM       4\n",
       "4A       3\n",
       "1        3\n",
       "7        3\n",
       "IG       3\n",
       "HH       3\n",
       "4C       3\n",
       "4        3\n",
       "2B       2\n",
       "4X       2\n",
       "GM       2\n",
       "3        2\n",
       "6P       1\n",
       "HU       1\n",
       "W        1\n",
       "3U       1\n",
       "1B       1\n",
       "5        1\n",
       "BM       1\n",
       "4R       1\n",
       "3H       1\n",
       "K        1\n",
       "2N       1\n",
       "T        1\n",
       "3P       1\n",
       "UC       1\n",
       "V        1\n",
       "BS       1\n",
       "4M       1\n",
       "G        1\n",
       "2E       1\n",
       "3M       1\n",
       "OR       1\n",
       "HG       1\n",
       "Name: FINANCIAL_CLASS_CODE, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_bs['FINANCIAL_CLASS_CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We turned 'RACE' and 'TOBACCO_STATUS_LABEL' to numeric categories for BASELINE dataset.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admissions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_ad = raw_admissiondt.select_dtypes(include=['object']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PATIENT_TYPE_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I     54806\n",
       "S       873\n",
       "E        53\n",
       "DO       10\n",
       "Name: PATIENT_TYPE_CODE, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_ad['PATIENT_TYPE_CODE'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    54806\n",
       "0      936\n",
       "Name: PATIENT_TYPE_CODE, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_nums = {\"PATIENT_TYPE_CODE\": {\"I\": 1, \"S\": 0, \"E\": 0, \"DO\": 0}}\n",
    "obj_ad.replace(clean_nums, inplace=True)\n",
    "obj_ad['PATIENT_TYPE_CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOSP_ROLLUP_GROUPING1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medicare              21728\n",
       "UPMC MC Managed       10136\n",
       "Security Blue          9311\n",
       "Other MC Managed       5797\n",
       "UPMC MA Managed        2008\n",
       "Highmark Commercia     1860\n",
       "UPMC Commercial        1647\n",
       "National Payers         845\n",
       "Gateway                 766\n",
       "Medicaid                707\n",
       "Other MA Managed        306\n",
       "Other                   258\n",
       "Self Pay                188\n",
       "Other Commercial        183\n",
       "MA Pending                2\n",
       "Name: HOSP_ROLLUP_GROUPING1, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_ad['HOSP_ROLLUP_GROUPING1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We turned 'PATIENT_TYPE_CODE' into numeric categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all non-numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_num = raw_baselinedt.drop(list(raw_baselinedt.select_dtypes('object').columns), axis = 1) \n",
    "obj_bs = obj_bs.drop(list(obj_bs.select_dtypes('object').columns), axis = 1) \n",
    "baseline_num = pd.concat([baseline_num, obj_bs], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_num = raw_admissiondt.drop(list(raw_admissiondt.select_dtypes('object').columns), axis = 1)\n",
    "obj_ad = obj_ad.drop(list(obj_ad.select_dtypes('object').columns), axis = 1)\n",
    "admissions_num = pd.concat([admissions_num, obj_ad], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the all-numeric baseline dataset has shape (12285, 293)\n",
      "the all-numeric admissions dataset has shape (55742, 144)\n"
     ]
    }
   ],
   "source": [
    "print(\"the all-numeric baseline dataset has shape\", baseline_num.shape)\n",
    "print(\"the all-numeric admissions dataset has shape\", admissions_num.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns with more than 1% NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clean = baseline_num.dropna(thresh=baseline_num.shape[0]-122, axis=1)\n",
    "admissions_clean = admissions_num.dropna(thresh=admissions_num.shape[0]-122, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12285, 131)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling 'HOSP_CR', 'HOSP_NA', 'HOSP_EGFR' with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinchenxie/miniconda3/envs/research_env/lib/python3.6/site-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "baseline_clean['HOSP_CR'].fillna(baseline_clean['HOSP_CR'].mean(), inplace=True)\n",
    "baseline_clean['HOSP_EGFR'].fillna(baseline_clean['HOSP_EGFR'].mean(), inplace=True)\n",
    "baseline_clean['HOSP_NA'].fillna(baseline_clean['HOSP_NA'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling 'ASA_00', 'INSULIN_00 ', ... with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clean = baseline_clean.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping and filling NA values:\n",
      "Baseline and admissions datasets have shape  (12285, 131) and (55742, 43) respectively.\n"
     ]
    }
   ],
   "source": [
    "print(\"After dropping and filling NA values:\")\n",
    "print(\"Baseline and admissions datasets have shape \",baseline_clean.shape, \n",
    "      'and' ,admissions_clean.shape, 'respectively.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join 2 datasets together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with procudures during hospitalization features\n",
    "\n",
    "- Some are included in both baseline and admissions datasets:\\\n",
    "CBGG, TAVR, SAVR_MECH, ... CRT_IMPLANT \n",
    "<br>\n",
    "\n",
    "- Some are only indluded in admissions datasets:\\\n",
    "PCI, IMPELLA. IABP, ..., BIV_ICD_IMPLANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For procedures that appeared both in admissions and baseline datasets, we want to set the feature=1 if the feature in either dataset contains 1. \\\n",
    "e.g. IF_CABG = MAX( MAX(admissions.CABG), baseline.PRIOR_CABG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# This function used to deal with procedure features that appeared in both baseline and admissions\n",
    "def if_procedure(proc, prior_proc, new_feature, baseline, admissions):\n",
    "    \"\"\"\n",
    "    proc: name of the procudure record in admission data\n",
    "    prior_proc: name of the procedure record in baseline data\n",
    "    new_feature: name of the new feature\n",
    "    baseline, admissions: baseline and adimissions datasets\n",
    "    @return: altered baseline dataset\n",
    "    \"\"\"\n",
    "    adm_patients = np.asarray(admissions.loc[admissions[proc]==1].rID)\n",
    "    baseline[new_feature] = 0\n",
    "    for i in np.unique(adm_patients):\n",
    "        baseline.at[i-1, new_feature] = 1\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_v1 = baseline_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0,
     2,
     5
    ]
   },
   "outputs": [],
   "source": [
    "list_proc = ['CABG','TAVR','SAVR_MECH','SAVR_BIO','SURG_AO_GRFT','ENDO_AO_GRFT','AO_VLV_REPAIR',\n",
    "            'SMVR','SPVR','STVR','POST_VAD','POST_TRANSPLANT','CRT_IMPLANT']\n",
    "list_preproc = ['PRIOR_CABG','PRIOR_TAVR','PRIOR_SAVR_MECH','PRIOR_SAVR_BIO','PRIOR_SURG_AO_GRFT',\n",
    "               'PRIOR_ENDO_AO_GRFT','PRIOR_AO_VLV_REPAIR','PRIOR_SMVR','PRIOR_SPVR',\n",
    "               'PRIOR_STVR','PRE_VAD','PRE_TRANSPLANT','PRE_CRT']\n",
    "list_new_feature = ['IF_CABG','IF_TAVR','IF_SAVTMECH','IF_SAVRBIO','IF_SURG_AOGRFT','IF_ENDO_AOGRFT',\n",
    "                   'IF_AOVLV_REPAIR','IF_SMVR','IF_SPVR','IF_STVR','IF_POSTVAD',\n",
    "                   'IF_POTRANSPLANT','IF_CRTIMPLANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing CABG\n",
      "doing TAVR\n",
      "doing SAVR_MECH\n",
      "doing SAVR_BIO\n",
      "doing SURG_AO_GRFT\n",
      "doing ENDO_AO_GRFT\n",
      "doing AO_VLV_REPAIR\n",
      "doing SMVR\n",
      "doing SPVR\n",
      "doing STVR\n",
      "doing POST_VAD\n",
      "doing POST_TRANSPLANT\n",
      "doing CRT_IMPLANT\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list_proc)):\n",
    "    print('doing',list_proc[i])\n",
    "    baseline_v1 = if_procedure(list_proc[i],list_preproc[i],list_new_feature[i],\n",
    "                              baseline_v1, admissions_clean)\n",
    "baseline_v1.drop(list_preproc, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For procedures that only appeared in admissions dataset, we add new features in baseline_v1.\\\n",
    "baseline_v1.new_feature = 1 if MAX(admissions.feature == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12285, 131)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_procedure2(proc, new_feature, baseline, admissions):\n",
    "    \"\"\"\n",
    "    proc: feature name of the procedure in admissions dataset\n",
    "    new_feature: the name of the procedure add into baseline_v1\n",
    "    baseline, admissions: baseline and admissions datasets\n",
    "    \"\"\"\n",
    "    adm_patients = np.asarray(admissions.loc[admissions[proc]==1].rID)\n",
    "    baseline[new_feature] = 0\n",
    "    for i in np.unique(adm_patients):\n",
    "#         print(i)\n",
    "        baseline.at[i-1, new_feature] = 1\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_proc2 = ['PCI','IMPELLA','IABP','ECMO','ABLATION','PACEMAKER_IMPLANT',\n",
    "              'ICD_IMPLANT','BIV_ICD_IMPLANT']\n",
    "list_new_features2 = ['IF_PCI','IF_IMPELLA','IF_IABP','IF_ECMO','IF_ABLATION',\n",
    "                     'IF_PACEMAKER','IF_ICDIMPLANT','IF_BIV_ICDIMPLANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing PCI\n",
      "doing IMPELLA\n",
      "doing IABP\n",
      "doing ECMO\n",
      "doing ABLATION\n",
      "doing PACEMAKER_IMPLANT\n",
      "doing ICD_IMPLANT\n",
      "doing BIV_ICD_IMPLANT\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list_proc2)):\n",
    "    print('doing',list_proc2[i])\n",
    "    baseline_v1 = if_procedure2(list_proc2[i], list_new_features2[i],\n",
    "                               baseline_v1, admissions_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_v1 = admissions_clean.copy()\n",
    "\n",
    "admission_v1.drop(list_proc, axis=1, inplace=True)\n",
    "admission_v1.drop(list_proc2, axis=1, inplace=True)\n",
    "\n",
    "admission_v1.drop('INDEX_HOSPITALIZATION', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55742, 21)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Admission_v2 group by patient ID and take the max of each feature\n",
    "admission_v1 = admission_v1.groupby('rID').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate two datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v1 = pd.merge(left=baseline_v1, right=admission_v1, left_on='rID', right_on='rID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['AGE_ADMISSION_y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4a56bf245b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AGE_ADMISSION_y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m         )\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['AGE_ADMISSION_y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "dataset_v1.drop('AGE_ADMISSION_y', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12285, 158)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v2 = dataset_v1.copy()\n",
    "for i in range(dataset_v2.shape[1]):\n",
    "    if (dataset_v2.iloc[:,i].max()==1):\n",
    "        pass\n",
    "    else:\n",
    "        dataset_v2.iloc[:,i] = (dataset_v2.iloc[:,i]-dataset_v2.iloc[:,i].mean())/dataset_v2.iloc[:,i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v2.to_excel('clean_HFdata_v1.xlsx', index = False, header = True, \n",
    "                    sheet_name='sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_norm = dataset_v1.copy()\n",
    "# for i in range(dataset_norm.shape[1]):\n",
    "#     if (dataset_norm.iloc[:,i].max()==1):\n",
    "#         pass\n",
    "#     else:\n",
    "#         dataset_norm.iloc[:,i] = (dataset_norm.iloc[:,i]-dataset_norm.iloc[:,i].mean())/dataset_norm.iloc[:,i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mortality status as target\n",
    "y = dataset_v1['CTB']\n",
    "X = dataset_v1.drop('CTB', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the patient ID label\n",
    "X = X.drop('rID',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X.fillna(8.475169e-01, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y, \n",
    "                                        train_size=0.80, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinchenxie/miniconda3/envs/research_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=900, multi_class='warn', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegressionCV(10, max_iter=900)\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_predicted = model_lr.predict(X_test)\n",
    "LR_accuracy = accuracy_score(y_test, LR_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Logistic Regression prediction has accuracy 0.8595848595848596\n"
     ]
    }
   ],
   "source": [
    "print('the Logistic Regression prediction has accuracy', LR_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators = 50, random_state = 0, max_depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_predicted = model_rf.predict(X_test)\n",
    "RF_accuracy = accuracy_score(y_test, RF_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Random Forest Classifier has accuracy 0.8616198616198616\n"
     ]
    }
   ],
   "source": [
    "print('the Random Forest Classifier has accuracy', RF_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Prepare the data for torch nn\n",
    "train_x = torch.tensor(X_train.values.astype(np.float32))\n",
    "train_y = torch.tensor(y_train.values.astype(np.int_))\n",
    "\n",
    "test_x = torch.tensor(X_test.values.astype(np.float32))\n",
    "test_y = torch.tensor(y_test.values.astype(np.int_))\n",
    "\n",
    "train_data = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=36, shuffle=True)\n",
    "\n",
    "validation_data = TensorDataset(test_x, test_y)\n",
    "validation_loader = DataLoader(dataset=validation_data, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [
     0,
     34,
     61
    ]
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # declaring some parameters\n",
    "        self.inputSize = 156\n",
    "        self.outputSize = 2\n",
    "        self.hidden1Size = 500\n",
    "#         self.hidden2Size = 200\n",
    "#         self.hidden3Size = 20\n",
    "\n",
    "        # layers of linear transformation\n",
    "        self.hidden1 = nn.Linear(self.inputSize, self.hidden1Size)\n",
    "#         self.hidden2 = nn.Linear(self.hidden1Size, self.hidden2Size)\n",
    "#         self.hidden3 = nn.Linear(self.hidden2Size, self.hidden3Size)\n",
    "        self.output = nn.Linear(self.hidden1Size, self.outputSize)\n",
    "\n",
    "\n",
    "        # # sigmoid activation and softmax output\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.sigmoid(self.hidden1(x))\n",
    "#         x = torch.sigmoid(self.hidden2(x))\n",
    "#         x = torch.sigmoid(self.hidden3(x))\n",
    "        y = F.softmax(self.output(x), dim=1)\n",
    "\n",
    "        return y\n",
    "    \n",
    "model = SimpleNN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch, log_interval=20):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # loop over batch from the training set\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "    return\n",
    "\n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "        val_loss /= len(validation_loader)\n",
    "        loss_vector.append(val_loss)\n",
    "        accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "        accuracy_vector.append(accuracy)\n",
    "\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-a4f5a22e579a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-7f7241026dda>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_interval)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "lossv, accv = [], []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the fully-connected NN has max accuracy', 2124/2457)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "clf = VotingClassifier([('logr', LogisticRegressionCV(10, max_iter=800)),\n",
    "                            ('rfor', RandomForestClassifier(n_estimators = 50, \n",
    "                                                            random_state = 0, max_depth=30)),\n",
    "                       ('svm', svm.SVC())])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-1eb9050a395e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvot_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvot_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvot_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvot_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "vot_predicted = clf.predict(X_test)\n",
    "vot_accuracy = accuracy_score(y_test, vot_predicted)\n",
    "vot_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The voting classifier has accuracy', vot_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = svm.SVC() # I chose RBF kernel here to project into infinite dimensions\n",
    "model_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predicted = model_svm.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predicted)\n",
    "svm_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The svm using Radial Basis Function as kernel has accuracy', svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(decomposition_data, labels_pred, path):\n",
    "    print('plotting visualization...')\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in decomposition_data:\n",
    "        x.append(i[0])\n",
    "        y.append(i[1])\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axes()\n",
    "    plt.scatter(x, y, c=labels_pred, marker=\".\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.savefig(path)\n",
    "    print('plot saved to ' + path + '\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "decomposition_data_test = tsne.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(decomposition_data_test, y_test, 'fig_truelabel.png')\n",
    "visualization(decomposition_data_test, RF_predicted, 'fig_rf_predict.png')\n",
    "visualization(decomposition_data_test, LR_predicted, 'fig_lr_predict.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
